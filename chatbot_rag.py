import os
import time
import logging
from dotenv import load_dotenv
from huggingface_hub import InferenceClient

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.tools import Tool
from langchain.utilities import SerpAPIWrapper
from langchain_core.runnables import RunnableLambda
from langchain.schema.output_parser import StrOutputParser

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Giá»›i háº¡n tÃ¬m kiáº¿m Google
search_count = 0
MAX_SEARCHES_PER_DAY = 5  # Giá»›i háº¡n tÃ¬m kiáº¿m má»—i ngÃ y
RESET_INTERVAL = 86400  # 24 giá» (tÃ­nh báº±ng giÃ¢y)
last_reset_time = time.time()

def can_search():
    """ Kiá»ƒm tra xem chatbot cÃ³ thá»ƒ tÃ¬m kiáº¿m trÃªn Google khÃ´ng. """
    global search_count, last_reset_time
    if time.time() - last_reset_time > RESET_INTERVAL:
        search_count = 0
        last_reset_time = time.time()
    return search_count < MAX_SEARCHES_PER_DAY

def increment_search_count():
    """ TÄƒng sá»‘ láº§n tÃ¬m kiáº¿m náº¿u chÆ°a Ä‘áº¡t giá»›i háº¡n. """
    global search_count
    if can_search():
        search_count += 1
        return True
    return False

# Táº£i dá»¯ liá»‡u vÄƒn báº£n
def load_documents(directory="data"):
    os.makedirs(directory, exist_ok=True)
    if not os.listdir(directory):
        with open(f"{directory}/sample.txt", "w", encoding="utf-8") as f:
            f.write("ÄÃ¢y lÃ  má»™t sá»‘ thÃ´ng tin máº«u vá» RAG.")
    try:
        loader = DirectoryLoader(directory, glob="**/*.txt", loader_cls=lambda file_path: TextLoader(file_path, encoding="utf-8"))
        return loader.load()
    except Exception as e:
        logger.error(f"Lá»—i khi táº£i tÃ i liá»‡u: {e}")
        return []

# Chia nhá» tÃ i liá»‡u
def split_documents(documents):
    if not documents:
        return []
    return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(documents)

# Táº¡o vector store
def create_vector_store(chunks, persist_directory="vector_store"):
    if not chunks:
        return None
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    return Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=persist_directory)

# Khá»Ÿi táº¡o Hugging Face AI
def initialize_llm():
    client = InferenceClient(
        model="mistralai/Mistral-7B-Instruct-v0.2", 
        token=os.getenv("HUGGINGFACE_API_KEY")
    )
    
    def generate_response(input_value):
        # Kiá»ƒm tra vÃ  xá»­ lÃ½ Ä‘áº§u vÃ o
        if isinstance(input_value, dict):
            context = input_value.get('context', '')
            question = input_value.get('question', '')
        elif isinstance(input_value, str):
            context = ''
            question = input_value
        else:
            context = ''
            question = str(input_value)
        
        # Táº¡o prompt theo template ban Ä‘áº§u
        full_prompt = f"""
        Báº¡n lÃ  má»™t trá»£ lÃ½ AI chÃ­nh xÃ¡c vÃ  chuyÃªn nghiá»‡p. HÃ£y tráº£ lá»i **tháº³ng vÃ o cÃ¢u há»i** dá»±a trÃªn dá»¯ liá»‡u cÃ³ sáºµn.  
        Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, hÃ£y **nÃ³i rÃµ ráº±ng báº¡n khÃ´ng biáº¿t** thay vÃ¬ Ä‘oÃ¡n bá»«a.  

        ðŸ“Œ **Quy táº¯c tráº£ lá»i**:  
        1ï¸âƒ£ **Tráº£ lá»i trá»±c tiáº¿p**, khÃ´ng lan man.  
        2ï¸âƒ£ **KhÃ´ng thÃªm thÃ´ng tin ngoÃ i lá»**.  
        3ï¸âƒ£ **Náº¿u cÃ³ thá»ƒ, trÃ­ch dáº«n nguá»“n dá»¯ liá»‡u**.  
        4ï¸âƒ£ **Náº¿u khÃ´ng biáº¿t, hÃ£y nÃ³i tháº³ng ráº±ng khÃ´ng cÃ³ thÃ´ng tin.**  

        ðŸ”Ž **Dá»¯ liá»‡u há»— trá»£**:  
        {context}  

        ðŸ“¢ **CÃ¢u há»i**: {question}  
        ðŸŽ¯ **Tráº£ lá»i chÃ­nh xÃ¡c**:  
        """
        
        # Sá»­ dá»¥ng InferenceClient Ä‘á»ƒ sinh vÄƒn báº£n
        response = client.text_generation(
            full_prompt, 
            max_new_tokens=150, 
            temperature=0.1
        )
        return response

    return RunnableLambda(generate_response)

# Thiáº¿t láº­p Google Search
def setup_google_search():
    return Tool(
        name="Google Search",
        func=SerpAPIWrapper(serpapi_api_key=os.getenv("SERPAPI_KEY")).run,
        description="TÃ¬m kiáº¿m thÃ´ng tin trÃªn Google."
    )

# Thiáº¿t láº­p chatbot
def setup_rag():
    documents = load_documents()
    chunks = split_documents(documents)
    vector_store = create_vector_store(chunks)

    if not vector_store:
        raise ValueError("KhÃ´ng thá»ƒ khá»Ÿi táº¡o vector store.")

    retriever = vector_store.as_retriever(search_kwargs={"k": 5})
    llm = initialize_llm()
    google_search = setup_google_search()

    # HÃ m truy xuáº¥t dá»¯ liá»‡u trÆ°á»›c khi tÃ¬m kiáº¿m trÃªn Google
    def retrieve_and_search(query):
        # Náº¿u ngÆ°á»i dÃ¹ng chá»‰ chÃ o há»i, tráº£ vá» pháº£n há»“i Ä‘Æ¡n giáº£n mÃ  khÃ´ng truy xuáº¥t dá»¯ liá»‡u
        greetings = ["xin chÃ o", "chÃ o báº¡n", "hello", "hi", "yo", "hey","chÃ o"]
        if query.lower() in greetings:
            return "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n hÃ´m nay?"
        docs = retriever.invoke(query)
        context = "\n\n".join([d.page_content for d in docs])

        if not context.strip():  
            if can_search():
                print("ðŸ” KhÃ´ng tÃ¬m tháº¥y trong dá»¯ liá»‡u ná»™i bá»™. Äang tÃ¬m kiáº¿m trÃªn Google...")
                increment_search_count()
                return google_search.run(query)
            else:
                return "âš ï¸ ÄÃ£ Ä‘áº¡t giá»›i háº¡n tÃ¬m kiáº¿m trÃªn Google hÃ´m nay."
        
        return context

    return (
        {"context": RunnablePassthrough() | retrieve_and_search, "question": RunnablePassthrough()}
        | llm
    )

# Cháº¡y chatbot
def main():
    print("ðŸ¤– Äang khá»Ÿi táº¡o chatbot RAG vá»›i Hugging Face API...")
    try:
        rag_chain = setup_rag()
        print("\nChatbot Ä‘Ã£ sáºµn sÃ ng! GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")

        while True:
            user_input = input("\nBáº¡n: ")

            if user_input.lower() == "exit":
                print("Táº¡m biá»‡t! ðŸ‘‹")
                break

            print("\nÄang xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n...")
            response = rag_chain.invoke(user_input)
            print(f"\nChatbot: {response}")

    except Exception as e:
        logger.error(f"Lá»—i: {e}")
        print(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o chatbot. Lá»—i: {e}")

if __name__ == "__main__":
    main()